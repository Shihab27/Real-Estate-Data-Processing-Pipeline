# -*- coding: utf-8 -*-
"""Capstone_1_Part_1 (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cn3ARaEBUhwLfSV-h0RQu36CGOurUEe1

# Capstone 1 - Part 1

### Dataset: Download CSV file from [here](https://drive.google.com/file/d/1LfquyGkEO45x35q8yvYzke8lswCfBu89/view?usp=sharing)

### Context & Problem statement:

This is a fictional data set that contains atmost 30 features of categorical and discreet data. These data are kind of both numerical and text values which help in analysing the employee data from hiring to firing and on boarding to attrition.  Dive into current available HR metrics to reduce the attrition rate and improve employee performance. Employee attrition has long been a significant worry for organizations due to the substantial investments of time, money, and effort in training new employees. When an employee departs, it results in overall losses for the company, including the cost of replacing and retraining, as well as disruptions in workflow. Moreover, attrition can erode trust among remaining employees, creating additional management challenges.

The HR Attrition dataset, albeit fictional, serves the purpose of identifying key factors that could play a pivotal role in determining which employees are more likely to leave the company and who is likely to stay. In this capstone, we delve into a thorough analysis of these influential factors and employ predictive modeling techniques to gain a deeper understanding, ultimately enabling us to make accurate predictions regarding employee attrition.

### Business use case:

- Brief overview of attrition within the organization
- Explore the main factors that lead to employee attrition
- Propose relevant contributors to Performance Ratings and calculate their correlations

### Goals/ Metrics:

- Identify top reasons for attrition and recommend further action steps to improve
- Point out key factors that drive employee performance

## TODO: Please make use of Python, Pandas, Numpy, Matplotlib and relevant libraries to do the following:

### Data Retrieval (1 pt)
- Extracting the dataset from the source (e.g., CSV file)
- Exploring the dataset structure, features, and target variable (attrition)
- Understanding the context and significance of each feature in relation to employee attrition

### Data preprocessing (2 pts)
- Cleaning the dataset to handle missing values, duplicates, and outliers
- Encoding categorical variables and transforming data types as necessary

### Feature Engineering & EDA (3 pts)
- Feature engineering to create new variables (e.g., employee tenure, performance scores) and do Exploratory Data Analysis (EDA)
- Analyzing factors contributing to employee attrition (e.g., age, job role, salary, work environment)
- Visualizing attrition rates across different demographic and employment-related variables
- Identifying correlations and patterns in the data to understand attrition drivers
- Make use of 1-d and 2-d explorations to know your data better.

### Effective Communication (2 pts)
- Please make use of markdown cells to communicate your thought process, why did you think of performing a step? what was the observation from the visualization? etc.
- Make sure the plots are correctly labelled.
- The code should be commented so that it is readable for the reviewer.

### Grading and Important Instructions
- Each of the above steps are mandatory and should be completed in good faith
- Make sure before submitting that the code is in fully working condition
- It is fine to make use of ChatGPT, stackoverflow type resources, just provide the reference links from where you got it
- Debugging is an art, if you find yourself stuck with errors, take help of stackoverflow and ChatGPT to resolve the issue and if it's still unresolved, reach out to me for help.
- You need to score atleast 7/10 to pass the project, anything less than that will be marked required, needing resubmission.
- Feedback will be provided on 3 levels (Awesome, Suggestion, & Required). Required changes are mandatory to be made.
- For submission, please upload the project on github and share the link to the file with us through LMS.

#### Write your code below and do not delete the above instructions
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
#Load the dataset
df = pd.read_csv("/content/HR-Analytics.csv")
df

#Show dataset information
print("Dataset Information:\n")
df.info()

#Check for missing values
print("\nMissing Values\n", df.isnull().sum())

#Show first few rows
print("\nFirst 5 rows\n", df.head())

#Summary of numeric features
print("Summary of numeric features", df.describe())

#Summary statistics of categorical variables
categorical_features = df.select_dtypes(include=['object']).columns
print("Summary features for categorical varibles\n", df[categorical_features].describe())

#Count plot for target variable (Attrition)
plt.figure(figsize=(6,4))
sns.countplot(x='Attrition', data=df, palette='coolwarm')
plt.title('Attrition Distribution')
plt.xlabel('Attrition')
plt.ylabel('Count')
plt.show()

#Show Class Distribution
print("\nAttrition Value Counts\n", df['Attrition'].value_counts())

#Feature Description
feature_description = {
    "Age": "Employee's age",
    "Attrition": "Whether the employee left the company (Yes/No)",
    "BusinessTravel": "How frequently the employee travels for work",
    "DailyRate": "Daily salary rate",
    "Department": "Department where the employee works",
    "DistanceFromHome": "Distance from home to workplace",
    "Education": "Education level (1-5)",
    "EducationField": "Field of study",
    "EnvironmentSatisfaction": "Satisfaction with workplace environment (1-4)",
    "Gender": "Employee's gender",
    "HourlyRate": "Hourly wage",
    "JobInvolvement": "Employee involvement in the job (1-4)",
    "JobLevel": "Seniority level of job (1-5)",
    "JobRole": "Specific job role",
    "JobSatisfaction": "Self-reported job satisfaction (1-4)",
    "MaritalStatus": "Marital status of the employee",
    "MonthlyIncome": "Monthly salary",
    "NumCompaniesWorked": "Total companies worked at before this one",
    "OverTime": "Whether the employee works overtime",
    "PercentSalaryHike": "Percentage increase in salary",
    "PerformanceRating": "Performance rating (1-4)",
    "StockOptionLevel": "Stock option level",
    "TotalWorkingYears": "Total years of work experience",
    "TrainingTimesLastYear": "Training sessions attended in last year",
    "WorkLifeBalance": "Self-reported work-life balance (1-4)",
    "YearsAtCompany": "Years spent at current company",
    "YearsInCurrentRole": "Years in current job role",
    "YearsSinceLastPromotion": "Years since last promotion",
    "YearsWithCurrManager": "Years worked with current manager"
}
print("\nFeature Descriptions:\n")
for feature, description in feature_description.items():
    print(f"{feature}: {description}")

#Convert Attrition to numeric for correlation analysis
df['Attrition'] = df['Attrition'].map({'Yes': 1, 'No': 0})

#Identify categorical variables
categorical_columns = df.select_dtypes(include=['object']).columns

#Encode categorical variables using label encoding
from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()

for col in categorical_columns:
  df[col] = label_encoder.fit_transform(df[col])

#Correlation Analysis
plt.figure(figsize=(12,6))
sns.heatmap(df.corr()['Attrition'].sort_values(ascending=False).to_frame(), annot=True, cmap="coolwarm")
plt.title("Correlation of Features with Attrition")
plt.show()
# plt.figure(figsize=(12, 6))
# sns.heatmap(df.corr(), annot=True, cmap="coolwarm")
# plt.title("Feature Correlation Heatmap")
# plt.show()

#Categorical Feature Analysis
categorical_features = ['BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus', 'OverTime']

for feature in categorical_features:
    plt.figure(figsize=(8,4))
    sns.countplot(x=feature, hue="Attrition", data=df, palette="coolwarm")
    plt.title(f'Attrition Rate By {feature}')
    plt.xticks(rotation=45)
    plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split

# Load dataset
file_path = "HR-Analytics.csv"  # Update the path if needed
df = pd.read_csv(file_path)

# Convert 'Attrition' to numeric
df['Attrition'] = df['Attrition'].map({'Yes': 1, 'No': 0})

# Identify categorical features
categorical_features = ['BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus', 'OverTime']

# Encode categorical variables
df_encoded = df.copy()
for col in categorical_features:
    # Check if the column exists in the DataFrame before encoding
    if col in df_encoded.columns:
        df_encoded[col] = LabelEncoder().fit_transform(df_encoded[col])

# Define Features (X) and Target (Y)
X = df_encoded.drop(columns=['Attrition'])
Y = df_encoded['Attrition']

# Split data into training and testing sets
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

# Scaling the data (Only apply to numeric features)
if X_train.shape[0] > 0:
    # Select only numeric features for scaling
    numeric_features = X_train.select_dtypes(include=np.number).columns
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train[numeric_features])
    X_test_scaled = scaler.transform(X_test[numeric_features])

    # Convert the scaled arrays back to DataFrames
    X_train_scaled = pd.DataFrame(X_train_scaled, columns=numeric_features, index=X_train.index)
    X_test_scaled = pd.DataFrame(X_test_scaled, columns=numeric_features, index=X_test.index)

    # Logistic Regression Model
    logreg = LogisticRegression(max_iter=1000)
    logreg.fit(X_train_scaled, Y_train)

    print("Logistic Regression Model trained successfully!")

    # Get feature importance (absolute coefficient values)
    logreg_importance = pd.DataFrame({'Feature': numeric_features, 'Importance': np.abs(logreg.coef_[0])})
    logreg_importance = logreg_importance.sort_values(by='Importance', ascending=False)

    # Plot Logistic Regression Feature Importance
    plt.figure(figsize=(12, 6))
    sns.barplot(x='Importance', y='Feature', data=logreg_importance, palette="coolwarm")
    plt.title("Feature Importance using Logistic Regression")
    plt.xlabel("Coefficient Magnitude (Absolute Value)")
    plt.ylabel("Feature")
    plt.show()

    print("\nFeature Importance (Logistic Regression):\n", logreg_importance)

# Feature Engineering: Creating New Variables
# Employee Tenure Ratio: YearsAtCompany / TotalWorkingYears (How long the employee stayed in this company)
df['TenureRatio'] = df['YearsAtCompany'] / df['TotalWorkingYears']
df['TenureRatio'].fillna(0, inplace=True)  # Fill NaN values (if any)

# Experience Gap: Difference between Total Working Years and Years at Company
df['ExperienceGap'] = df['TotalWorkingYears'] - df['YearsAtCompany']

# Recent Promotion Indicator: Binary flag for employees promoted in the last 2 years
df['RecentPromotion'] = df['YearsSinceLastPromotion'].apply(lambda x: 1 if x <= 2 else 0)

# Performance Score: Combining Performance Rating & Percent Salary Hike
df['PerformanceScore'] = df['PerformanceRating'] * df['PercentSalaryHike']

# Work-Life Imbalance: Creating a binary flag for poor Work-Life Balance
df['WorkLifeImbalance'] = df['WorkLifeBalance'].apply(lambda x: 1 if x <= 2 else 0)


print("\nNew features added! Dataset now has:", df.shape[1], "columns.")

# Recent Promotion vs. Attrition
plt.figure(figsize=(8, 4))
sns.countplot(x="RecentPromotion", hue="Attrition", data=df, palette="coolwarm")
plt.title("Attrition Rate by Recent Promotion")
plt.show()

# Work-Life Imbalance vs. Attrition
plt.figure(figsize=(8, 4))
sns.countplot(x="WorkLifeImbalance", hue="Attrition", data=df, palette="coolwarm")
plt.title("Attrition Rate by Work-Life Imbalance")
plt.show()

# Attrition Rate by Overtime
plt.figure(figsize=(8, 4))
sns.countplot(x="OverTime", hue="Attrition", data=df, palette="coolwarm")
plt.title("Attrition Rate by Overtime")
plt.xlabel("OverTime")
plt.ylabel("Attrition Rate")
plt.show()

# Demographic Factors Affecting Attrition
demographic_features = ['Age', 'Gender', 'MaritalStatus', 'Education', 'EducationField']

for feature in demographic_features:
    plt.figure(figsize=(8, 4))
    sns.countplot(x=feature, hue="Attrition", data=df, palette="coolwarm")
    plt.title(f'Attrition Rate by {feature}')
    plt.xticks(rotation=45)
    plt.show()

# Employment Factors Affecting Attrition**
employment_features = ['Department', 'JobRole', 'JobLevel', 'OverTime', 'WorkLifeBalance', 'YearsAtCompany']

for feature in employment_features:
    plt.figure(figsize=(8, 4))
    sns.countplot(x=feature, hue="Attrition", data=df, palette="coolwarm")
    plt.title(f'Attrition Rate by {feature}')
    plt.xticks(rotation=45)
    plt.show()

# Save engineered dataset
df.to_csv("Enhanced_HR_Analytics.csv", index=False)
print("\nEnhanced dataset saved as 'Enhanced_HR_Analytics.csv'.")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Load dataset
file_path = "Enhanced_HR_Analytics.csv"  # Ensure the enhanced dataset is used
df = pd.read_csv(file_path)

# Convert 'Attrition' to categorical
df['Attrition'] = df['Attrition'].map({1: "Yes", 0: "No"})

# 1D Exploration (Feature Distributions & Summary Statistics)
print("\nDataset Overview:\n", df.info())
print("\nStatistical Summary:\n", df.describe())

# Checking missing values
print("\n🛠 Missing Values:\n", df.isnull().sum())

# Histogram for numerical features
numerical_features = ['Age', 'MonthlyIncome', 'DistanceFromHome', 'TotalWorkingYears', 'YearsAtCompany']

for feature in numerical_features:
    plt.figure(figsize=(8, 4))
    sns.histplot(df[feature], bins=30, kde=True, color="blue")
    plt.title(f'Distribution of {feature}')
    plt.xlabel(feature)
    plt.ylabel('Count')
    plt.show()

# Count plot for categorical features
categorical_features = ['Gender', 'MaritalStatus', 'JobRole', 'Department', 'OverTime']

for feature in categorical_features:
    plt.figure(figsize=(8, 4))
    sns.countplot(x=feature, data=df, palette="coolwarm")
    plt.title(f'Count of Employees by {feature}')
    plt.xticks(rotation=45)
    plt.show()

## 2D Exploration (Feature Relationships)**

#  Boxplots to compare numerical features across Attrition categories
for feature in numerical_features:
    plt.figure(figsize=(8, 4))
    sns.boxplot(x="Attrition", y=feature, data=df, palette="coolwarm")
    plt.title(f'Attrition Impact on {feature}')
    plt.show()

# Scatter Plots for key numerical features
key_features = ['MonthlyIncome', 'TotalWorkingYears', 'YearsAtCompany', 'Age']

for feature in key_features:
    plt.figure(figsize=(8, 4))
    sns.scatterplot(x=df[feature], y=df['MonthlyIncome'], hue=df['Attrition'], alpha=0.7)
    plt.title(f'Attrition Relationship: {feature} vs. Monthly Income')
    plt.xlabel(feature)
    plt.ylabel('Monthly Income')
    plt.legend()
    plt.show()

# Attrition Rate by Overtime
plt.figure(figsize=(8, 4))
sns.barplot(x="OverTime", y=df["Attrition"].map({'Yes': 1, 'No': 0}), data=df, palette="coolwarm")
plt.title("Attrition Rate by Overtime")
plt.xlabel("OverTime")
plt.ylabel("Attrition Rate")
plt.show()

# Attrition Rate by Work-Life Balance
plt.figure(figsize=(8, 4))
sns.barplot(x="WorkLifeBalance", y=df["Attrition"].map({'Yes': 1, 'No': 0}), data=df, palette="coolwarm")
plt.title("Attrition Rate by Work-Life Balance")
plt.xlabel("Work-Life Balance Score")
plt.ylabel("Attrition Rate")
plt.show()

# Attrition by Age Group
df['AgeGroup'] = pd.cut(df['Age'], bins=[18, 25, 35, 45, 55, 65], labels=["18-25", "26-35", "36-45", "46-55", "56-65"])
plt.figure(figsize=(8, 4))
sns.countplot(x='AgeGroup', hue='Attrition', data=df, palette="coolwarm")
plt.title('Attrition Rate by Age Group')
plt.xlabel('Age Group')
plt.ylabel('Count')
plt.show()

# Removing Duplicates
df.drop_duplicates(inplace=True)
print("Duplicates removed. New shape:", df.shape)

# Handling Outliers (Using IQR Method)**
def remove_outliers(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]

# Apply IQR filter to numerical columns
for col in numerical_cols:
    df = remove_outliers(df, col)

print("Outliers removed. New shape:", df.shape)



# Encoding Categorical Variables
label_encoder = LabelEncoder()
for col in categorical_cols:
    df[col] = label_encoder.fit_transform(df[col])

print("\nCategorical encoding completed.")

# Transforming Data Types
df = df.astype({'Attrition': 'int64'})  # Ensure Attrition is numeric

# Display cleaned dataset summary
print("\nFinal Dataset Summary:")
print(df.info())

# Save cleaned dataset
df.to_csv("Cleaned_HR_Analytics.csv", index=False)
print("\nCleaned dataset saved as 'Cleaned_HR_Analytics.csv'.")

